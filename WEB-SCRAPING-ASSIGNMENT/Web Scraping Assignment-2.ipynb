{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10cbdc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import #  \n",
    "import time\n",
    "from selenium import webdriver\n",
    "# import chrome in webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "#import pandas \n",
    "import pandas as pd\n",
    "#import selenium webdriver webdriver\n",
    "from selenium.webdriver.common.keys import Keys as key\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c78d6",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. Youhave to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "    This task will be done in following steps:\n",
    "    1. First get the webpage https://www.naukri.com/\n",
    "    2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "    location” field.\n",
    "    3. Then click the search button.\n",
    "    4. Then scrape the data for the first 10 jobs results you get.\n",
    "    5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59aa5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9e9d1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = webdriver.Chrome(executable_path='chromedriver.exe')\n",
    "doc.get('https://www.naukri.com/')\n",
    "doc.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee4a9f",
   "metadata": {},
   "source": [
    "# 2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b9bc7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter Data Analyst using calss\n",
    "doc.find_element_by_class_name(\"sugInp\").send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2943847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter bangalore in location\n",
    "doc.find_element_by_id(\"qsb-location-sugg\").send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d00bd",
   "metadata": {},
   "source": [
    "# 3. Then click the search button`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e058bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on search button\n",
    "doc.find_element_by_class_name('btn').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c6844",
   "metadata": {},
   "source": [
    "# 4. Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7df5ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful scrap\n"
     ]
    }
   ],
   "source": [
    "#create 5 blank list variable\n",
    "designation = []\n",
    "company_name = []\n",
    "exp = []\n",
    "location=[]\n",
    "\n",
    "#for_loop run 10 times\n",
    "for i in range(1,11):\n",
    "    #using xpath scrape data thnen uses loop xpath run 10 time or scrape 1st 10 data\n",
    "    designation.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/a').text)\n",
    "    company_name.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/div/a[1]').text)\n",
    "    exp.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/ul/li[1]/span').text)\n",
    "    location.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/ul/li[3]/span').text)\n",
    "    \n",
    "print('successful scrap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef3a076",
   "metadata": {},
   "source": [
    "# 5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7e48c8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience required</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead - Data Analyst / Scientist</td>\n",
       "      <td>Axim Technologies</td>\n",
       "      <td>12-14 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Snaphunt</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Business Data Analyst - Database Design/Mining</td>\n",
       "      <td>AugmatrixGo</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst - KPO</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst - Supporting Audits</td>\n",
       "      <td>Visa</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Glance</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Glance IT Solution</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Arcworth Strategy LLP</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Job title               Company Name  \\\n",
       "0                 Lead - Data Analyst / Scientist          Axim Technologies   \n",
       "1                             Senior Data Analyst         Schneider Electric   \n",
       "2                                    Data Analyst                   Snaphunt   \n",
       "3  Business Data Analyst - Database Design/Mining                AugmatrixGo   \n",
       "4                       Senior Data Analyst - KPO  Huquo Consulting Pvt. Ltd   \n",
       "5         Senior Data Analyst - Supporting Audits                       Visa   \n",
       "6                                    Data Analyst                   Flipkart   \n",
       "7                             Senior Data Analyst                     Glance   \n",
       "8                             Senior Data Analyst         Glance IT Solution   \n",
       "9                             Senior Data Analyst      Arcworth Strategy LLP   \n",
       "\n",
       "  Experience required                               Location  \n",
       "0           12-14 Yrs                    Bangalore/Bengaluru  \n",
       "1             0-2 Yrs                    Bangalore/Bengaluru  \n",
       "2             0-2 Yrs                    Bangalore/Bengaluru  \n",
       "3             2-5 Yrs                    Bangalore/Bengaluru  \n",
       "4            7-12 Yrs  Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "5             5-8 Yrs                    Bangalore/Bengaluru  \n",
       "6             1-2 Yrs                    Bengaluru/Bangalore  \n",
       "7             1-6 Yrs                    Bangalore/Bengaluru  \n",
       "8             1-6 Yrs                    Bangalore/Bengaluru  \n",
       "9             2-4 Yrs                                 Remote  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame using pandas\n",
    "pd.DataFrame({'Job title':designation,'Company Name':company_name,'Experience required':exp,'Location':location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3021478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb7ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fee65684",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "    1. First get the webpage https://www.naukri.com/\n",
    "    2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "    location” field.\n",
    "    3. Then click the search button.\n",
    "    4. Then scrape the data for the first 10 jobs results you get.\n",
    "    5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc434727",
   "metadata": {},
   "source": [
    "# 1. First get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50308d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = webdriver.Chrome(executable_path='chromedriver.exe')\n",
    "doc.get('https://www.naukri.com/')\n",
    "doc.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36683ff5",
   "metadata": {},
   "source": [
    "# 2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b04e66df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter Data Scientist using calss\n",
    "doc.find_element_by_class_name(\"sugInp\").send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd9c22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter bangalore in location\n",
    "doc.find_element_by_id(\"qsb-location-sugg\").send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b364eb2",
   "metadata": {},
   "source": [
    "# 3. Then click the search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7a77281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on search button\n",
    "doc.find_element_by_class_name('btn').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dca1781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful scrap\n"
     ]
    }
   ],
   "source": [
    "#create 5 blank list variable\n",
    "designation = []\n",
    "company_name = []\n",
    "location=[]\n",
    "\n",
    "#for_loop run 10 times\n",
    "for i in range(1,11):\n",
    "    #using xpath scrape data thnen uses loop xpath run 10 time or scrape 1st 10 data\n",
    "    designation.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/a').text)\n",
    "    company_name.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/div/a[1]').text)\n",
    "    location.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/ul/li[3]/span').text)\n",
    "    \n",
    "print('successful scrap')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085dce7",
   "metadata": {},
   "source": [
    "# 5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "497041d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global Tax Automation &amp; Operations | Data Scie...</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead - Data Analyst / Scientist</td>\n",
       "      <td>Axim Technologies</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Job opening with Wipro For Data Scientist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Spark ML Data Scientist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spark ML Data Scientist</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Azure ML Data Scientist</td>\n",
       "      <td>TCS</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Greenizon Agritech Consultancy</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Diverse Lynx</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job title  \\\n",
       "0  Global Tax Automation & Operations | Data Scie...   \n",
       "1                              Senior Data Scientist   \n",
       "2                    Lead - Data Analyst / Scientist   \n",
       "3          Job opening with Wipro For Data Scientist   \n",
       "4                                   Data Scientist I   \n",
       "5                            Spark ML Data Scientist   \n",
       "6                            Spark ML Data Scientist   \n",
       "7                            Azure ML Data Scientist   \n",
       "8                              Senior Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                     Company Name  \\\n",
       "0                            Dell   \n",
       "1               Fractal Analytics   \n",
       "2               Axim Technologies   \n",
       "3                           Wipro   \n",
       "4                       Delhivery   \n",
       "5                           Wipro   \n",
       "6                           Wipro   \n",
       "7                             TCS   \n",
       "8  Greenizon Agritech Consultancy   \n",
       "9                    Diverse Lynx   \n",
       "\n",
       "                                            Location  \n",
       "0                                Bangalore/Bengaluru  \n",
       "1  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...  \n",
       "2                                Bangalore/Bengaluru  \n",
       "3  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5  Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru  \n",
       "6  Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru  \n",
       "7        Hyderabad/Secunderabad, Bangalore/Bengaluru  \n",
       "8                                Bangalore/Bengaluru  \n",
       "9                                Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame using pandas\n",
    "pd.DataFrame({'Job title':designation,'Company Name':company_name,'Location':location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85bc001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53913f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f3d9c7a",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "    You have to use the location and salary filter.\n",
    "    You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "    You have to scrape the job-title, job-location, company name, experience required.\n",
    "    The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "    The task will be done as shown in the below steps:\n",
    "    1. first get the webpage https://www.naukri.com/\n",
    "    2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "    3. Then click the search button.\n",
    "    4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "    5. Then scrape the data for the first 10 jobs results you get.\n",
    "    6. Finally create a dataframe of the scraped data.\n",
    "    Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79681826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable and add path chromedrive path\n",
    "    # doc = Chrome(executable_path='C:\\chromedriver.exe')\n",
    "\n",
    "#upload chrome driver in jupiter notebook then use \n",
    "doc = Chrome(\"chromedriver.exe\")\n",
    "#open webpage\n",
    "#maximize window\n",
    "doc.maximize_window()\n",
    "#open chrome\n",
    "url = 'https://www.naukri.com/'\n",
    "doc.get(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78b4e5",
   "metadata": {},
   "source": [
    "# 2. Enter “Data Scientist” in “Skill, Designations, and Companies” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a1a5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter data scientist using class\n",
    "doc.find_element_by_class_name('sugInp').send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8f3a1",
   "metadata": {},
   "source": [
    "# 3. Then click the search button.¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ebc8c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click search button\n",
    "doc.find_element_by_class_name('btn').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6bc8f0",
   "metadata": {},
   "source": [
    "# 4. Then apply the location filter and salary filter by checking the respective boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec36540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click location filter using css selector\n",
    "doc.find_element_by_css_selector('[Title=\"Delhi / NCR\"]').click()\n",
    "# wait 3 sec\n",
    "time.sleep(5)\n",
    "#click salary filter using css selector\n",
    "doc.find_element_by_css_selector('[Title=\"3-6 Lakhs\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac093885",
   "metadata": {},
   "source": [
    "# 5. Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e96fb3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful scrap\n"
     ]
    }
   ],
   "source": [
    "#create 5 blank list variable\n",
    "designation = []\n",
    "company_name = []\n",
    "exp = []\n",
    "location=[]\n",
    "\n",
    "#for_loop run 10 times\n",
    "for i in range(1,11):\n",
    "    #using xpath scrape data thnen uses loop xpath run 10 time or scrape 1st 10 data\n",
    "    designation.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/a').text)\n",
    "    company_name.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/div/a[1]').text)\n",
    "    exp.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/ul/li[1]/span').text)\n",
    "    location.append(doc.find_element_by_xpath(f'/html/body/div[1]/div[3]/div[2]/section[2]/div[2]/article[{i}]/div[1]/div[1]/ul/li[3]/span').text)\n",
    "print('successful scrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "826dc193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience required</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Openings For Jr/mid/Sr level data Scientists</td>\n",
       "      <td>Pluto seven business solutions (p) limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Teleperformance</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist role</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist role</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst / Data Scientist / Business Analy...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Noida, New Delhi, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Internship</td>\n",
       "      <td>iHackers Inc</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job title  \\\n",
       "0                            Senior Data Scientist I   \n",
       "1       Openings For Jr/mid/Sr level data Scientists   \n",
       "2                                     Data Scientist   \n",
       "3                                Data Scientist role   \n",
       "4                                Data Scientist role   \n",
       "5                   Urgent Hiring For Data Scientist   \n",
       "6                   Urgent Hiring For Data Scientist   \n",
       "7  Data Analyst / Data Scientist / Business Analy...   \n",
       "8                                     Data Scientist   \n",
       "9                          Data Scientist Internship   \n",
       "\n",
       "                                 Company Name Experience required  \\\n",
       "0                                   Delhivery             3-7 Yrs   \n",
       "1  Pluto seven business solutions (p) limited             2-6 Yrs   \n",
       "2                             Teleperformance             4-9 Yrs   \n",
       "3     Mount Talent Consulting Private Limited             1-3 Yrs   \n",
       "4     Mount Talent Consulting Private Limited             1-3 Yrs   \n",
       "5     Mount Talent Consulting Private Limited             1-6 Yrs   \n",
       "6     Mount Talent Consulting Private Limited             1-6 Yrs   \n",
       "7                   GABA Consultancy services             0-0 Yrs   \n",
       "8                              Country Veggie             1-3 Yrs   \n",
       "9                                iHackers Inc             0-1 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0                                   Gurgaon/Gurugram  \n",
       "1  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...  \n",
       "2                          Gurgaon/Gurugram, Chennai  \n",
       "3  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...  \n",
       "4  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...  \n",
       "5              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "6              Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "7                      Noida, New Delhi, Delhi / NCR  \n",
       "8  Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...  \n",
       "9                                          New Delhi  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame using pandas\n",
    "pd.DataFrame({'Job title':designation,'Company Name':company_name,'Experience required':exp,'Location':location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dab550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c944bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc24c941",
   "metadata": {},
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "    1. Brand\n",
    "    2. Product Description\n",
    "    3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1376e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable and add path chromedrive path\n",
    "    # doc = Chrome(executable_path='C:\\chromedriver.exe')\n",
    "\n",
    "#upload chrome driver in jupiter notebook then use \n",
    "doc = Chrome(\"chromedriver.exe\")\n",
    "#open webpage\n",
    "#maximize window\n",
    "doc.maximize_window()\n",
    "#open chrome\n",
    "url = 'https://www.flipkart.com/'\n",
    "doc.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52fbe06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut page \n",
    "time.sleep(4)\n",
    "doc.find_element_by_xpath('//div[@class=\"_2QfC02\"]//button[@class=\"_2KpZ6l _2doB4z\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fe201f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using class enter sneakers\n",
    "doc.find_element_by_class_name('_3704LK').send_keys('sunglasses')\n",
    "#wait 5sec\n",
    "time.sleep(2)\n",
    "#using class click search button \n",
    "doc.find_element_by_class_name('L0Z3Pu').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "783aec79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape successfull\n"
     ]
    }
   ],
   "source": [
    "#3blank list variable create\n",
    "brand = []\n",
    "Product_Description = []\n",
    "price = []\n",
    "\n",
    "#create variable store value 11\n",
    "run = 11\n",
    "for link in range(1,4):\n",
    "    #change page url\n",
    "    doc.get(f'https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page={link}')\n",
    "    time.sleep(2)\n",
    "    # loop run 10 times  because element class defind 4*10 1st use 10 time and 4 time\n",
    "    if link <=3:\n",
    "        if link ==3:   \n",
    "            run = 6\n",
    "        #loop run 10 time but page=3 run only 6 time \n",
    "        for i in range(1,run):\n",
    "            for p in range(1,5):\n",
    "\n",
    "                brand.append(doc.find_element_by_xpath(f'//div[@class=\"_1YokD2 _3Mn1Gg\"]//div[@class=\"_1AtVbE col-12-12\"][{i}]/div[1]/div[{p}]//div[@class=\"_2WkVRV\"]').text)\n",
    "                Product_Description.append(doc.find_element_by_xpath(f'//div[@class=\"_1YokD2 _3Mn1Gg\"]//div[@class=\"_1AtVbE col-12-12\"][{i}]/div[1]/div[{p}]//a[@class=\"IRpwTa\"]').text)\n",
    "                price.append(doc.find_element_by_xpath(f'//div[@class=\"_1YokD2 _3Mn1Gg\"]//div[@class=\"_1AtVbE col-12-12\"][{i}]/div[1]/div[{p}]//div[@class=\"_30jeq3\"]').text)\n",
    "print('Scrape successfull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7bbd127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sunglasses brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>sunglasses Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Aviator Sunglasses (53)</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart UV Protection Aviator Sunglasses (53)</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Urbanic</td>\n",
       "      <td>Others Oval Sunglasses (Free Size)</td>\n",
       "      <td>₹675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>IDEE</td>\n",
       "      <td>Mirrored, UV Protection Aviator Sunglasses (18)</td>\n",
       "      <td>₹1,229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sunglasses brand                                Product Description  \\\n",
       "0     VINCENT CHASE  by Lenskart UV Protection Aviator Sunglasses (53)   \n",
       "1            GANSTA              UV Protection Aviator Sunglasses (57)   \n",
       "2              SRPM             UV Protection Wayfarer Sunglasses (56)   \n",
       "3         Elligator                UV Protection Round Sunglasses (54)   \n",
       "4    kingsunglasses                UV Protection Round Sunglasses (54)   \n",
       "..              ...                                                ...   \n",
       "95    VINCENT CHASE  by Lenskart UV Protection Aviator Sunglasses (53)   \n",
       "96          Urbanic                 Others Oval Sunglasses (Free Size)   \n",
       "97   kingsunglasses         UV Protection Round Sunglasses (Free Size)   \n",
       "98             IDEE    Mirrored, UV Protection Aviator Sunglasses (18)   \n",
       "99    VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...   \n",
       "\n",
       "   sunglasses Price  \n",
       "0              ₹999  \n",
       "1              ₹269  \n",
       "2              ₹188  \n",
       "3              ₹248  \n",
       "4              ₹188  \n",
       "..              ...  \n",
       "95             ₹999  \n",
       "96             ₹675  \n",
       "97             ₹279  \n",
       "98           ₹1,229  \n",
       "99             ₹999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame\n",
    "pd.DataFrame({'sunglasses brand':brand,'Product Description':Product_Description,'sunglasses Price':price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a18230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010db6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643797ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ddbc63c",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-%20earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC%20TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d1543b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable and add path chromedrive path\n",
    "    # doc = Chrome(executable_path='C:\\chromedriver.exe')\n",
    "\n",
    "#upload chrome driver in jupiter notebook then use \n",
    "doc = Chrome(\"chromedriver.exe\")\n",
    "#open webpage\n",
    "#maximize window\n",
    "doc.maximize_window()\n",
    "#open chrome\n",
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-%20earpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC%20TSVZAXUHGREPBFGI&marketplace'\n",
    "doc.get(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6774a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click all reviews\n",
    "doc.find_element_by_xpath('//div[@class=\"_3UAT2v _16PBlm\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9ad84142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful scrap\n"
     ]
    }
   ],
   "source": [
    "#create 3 blank variable:\n",
    "rating = []\n",
    "review_summary = []\n",
    "full_review = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    doc.get(f'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3IXQLM&marketplace=FLIPKART&page={i}')\n",
    "    time.sleep(3)\n",
    "    for i in range(2,12):\n",
    "        try:\n",
    "            rating.append(doc.find_element_by_xpath(f'//div[@class=\"_1AtVbE col-12-12\"][{i}]//div[@class=\"_3LWZlK _1rdVr6 _1BLPMq\"]').text)\n",
    "        except:\n",
    "            rating.append(doc.find_element_by_xpath(f'//div[@class=\"_1AtVbE col-12-12\"][{i}]//div[@class=\"_3LWZlK _1BLPMq\"]').text)\n",
    "        finally:\n",
    "            review_summary.append(doc.find_element_by_xpath(f'//div[@class=\"_1AtVbE col-12-12\"][{i}]//p[@class=\"_2-N8zT\"]').text)\n",
    "            full_review.append(doc.find_element_by_xpath(f'//div[@class=\"_1AtVbE col-12-12\"][{i}]//div[@class=\"t-ZTKy\"]').text)\n",
    "\n",
    "\n",
    "print('successful scrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd0c4d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################\n",
      "#  First 100 reviews  #\n",
      "#######################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iphone-11 rating</th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Camera is excellent just lack of telephoto mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iphone-11 rating       Review summary  \\\n",
       "0                 5            Brilliant   \n",
       "1                 5       Simply awesome   \n",
       "2                 5  Best in the market!   \n",
       "3                 5     Perfect product!   \n",
       "4                 5    Worth every penny   \n",
       "..              ...                  ...   \n",
       "95                5            Must buy!   \n",
       "96                5    Terrific purchase   \n",
       "97                5              Awesome   \n",
       "98                3       Decent product   \n",
       "99                5            Wonderful   \n",
       "\n",
       "                                          Full review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  Camera is excellent just lack of telephoto mod...  \n",
       "96  I use a Note10+ and have been using both iOS a...  \n",
       "97  The phone is completely good\\nAs far as camera...  \n",
       "98  Everything u ll like it when u use this iPhone...  \n",
       "99  Nice value for money good and best price I pho...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use pandas create daraframe\n",
    "print('''#######################\n",
    "#  First 100 reviews  #\n",
    "#######################''')\n",
    "pd.DataFrame({'iphone-11 rating':rating,'Review summary':review_summary,'Full review':full_review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65b15ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca880382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5fb209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "695a5454",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the search field.\n",
    "    You have to scrape 4 attributes of each sneaker:\n",
    "    1. Brand\n",
    "    2. Product Description\n",
    "    3. Price\n",
    "    As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ce5e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable and add path chromedrive path\n",
    "    # doc = Chrome(executable_path='C:\\chromedriver.exe')\n",
    "\n",
    "#upload chrome driver in jupiter notebook then use \n",
    "doc = Chrome(\"chromedriver.exe\")\n",
    "#open webpage\n",
    "#maximize window\n",
    "doc.maximize_window()\n",
    "#open chrome\n",
    "url = 'https://www.flipkart.com/'\n",
    "doc.get(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79189d48",
   "metadata": {},
   "source": [
    "# search  “sneakers”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab7c866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut page \n",
    "time.sleep(4)\n",
    "doc.find_element_by_xpath('//div[@class=\"_2QfC02\"]//button[@class=\"_2KpZ6l _2doB4z\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecf05874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using class enter sneakers\n",
    "doc.find_element_by_class_name('_3704LK').send_keys('sneakers')\n",
    "#wait 5sec\n",
    "time.sleep(2)\n",
    "#using class click search button \n",
    "doc.find_element_by_class_name('L0Z3Pu').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23414e2f",
   "metadata": {},
   "source": [
    "# You have to scrape 4 attributes of each sneaker:\n",
    "    1. Brand\n",
    "    2. Product Description\n",
    "    3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a4abb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape successfull\n"
     ]
    }
   ],
   "source": [
    "#3blank list variable create\n",
    "brand = []\n",
    "Product_Description = []\n",
    "price = []\n",
    "\n",
    "#create variable store value 11\n",
    "run = 11\n",
    "for link in range(1,4):\n",
    "    #change page url\n",
    "    doc.get(f'https://www.flipkart.com/search?q=sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page={link}')\n",
    "    time.sleep(2)\n",
    "    # loop run 10 times  because element class defind 4*10 1st use 10 time and 4 time\n",
    "    if link <=3:\n",
    "        if link ==3:   \n",
    "            run = 6\n",
    "        #loop run 10 time but page=3 run only 6 time \n",
    "        for i in range(1,run):\n",
    "            for p in range(1,5):\n",
    "\n",
    "                brand.append(doc.find_element_by_xpath(f'//div[@class=\"_1AtVbE col-12-12\"][{i}]//div[@class=\"_13oc-S\"]//div[{p}]//div[@class=\"_1xHGtK _373qXS\"]//div[@class=\"_2WkVRV\"]').text)\n",
    "                Product_Description.append(doc.find_element_by_xpath(f'//div[@class=\"_1AtVbE col-12-12\"][{i}]//div[@class=\"_13oc-S\"]//div[{p}]//div[@class=\"_2B099V\"]').text.split(\"\\n\")[1])\n",
    "                price.append(doc.find_element_by_xpath(f'//div[@class=\"_1AtVbE col-12-12\"][{i}]//div[@class=\"_13oc-S\"]//div[{p}]//div[@class=\"_30jeq3\"]').text)\n",
    "print('Scrape successfull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cae9155a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoes brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Shoes Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Strollin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JK PORT</td>\n",
       "      <td>Fashionable Mens Grey Casual Shoes, Party Wear...</td>\n",
       "      <td>₹489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern &amp; Trendy Collection Combo Pack of 02 Sh...</td>\n",
       "      <td>₹447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NAUTICA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>SM-322 Sneakers For Men</td>\n",
       "      <td>₹891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>HRDK</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Trendy Sport Shoes For Men Pack Of 2 Sneakers ...</td>\n",
       "      <td>₹735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>GIWERO</td>\n",
       "      <td>Giwero Grand sneakers for Men,Boys Sneakers Fo...</td>\n",
       "      <td>₹1,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Shoes brand                                Product Description  \\\n",
       "0         Strollin                                   Sneakers For Men   \n",
       "1          JK PORT  Fashionable Mens Grey Casual Shoes, Party Wear...   \n",
       "2   luxury fashion  Luxury Fashionable casual sneaker shoes Sneake...   \n",
       "3         URBANBOX                          Sneakers Sneakers For Men   \n",
       "4           BRUTON  Modern & Trendy Collection Combo Pack of 02 Sh...   \n",
       "..             ...                                                ...   \n",
       "95         NAUTICA                                   Sneakers For Men   \n",
       "96           SPARX                            SM-322 Sneakers For Men   \n",
       "97            HRDK                                   Sneakers For Men   \n",
       "98           BIRDE  Trendy Sport Shoes For Men Pack Of 2 Sneakers ...   \n",
       "99          GIWERO  Giwero Grand sneakers for Men,Boys Sneakers Fo...   \n",
       "\n",
       "   Shoes Price  \n",
       "0         ₹489  \n",
       "1         ₹489  \n",
       "2         ₹449  \n",
       "3         ₹220  \n",
       "4         ₹447  \n",
       "..         ...  \n",
       "95      ₹1,899  \n",
       "96        ₹891  \n",
       "97        ₹374  \n",
       "98        ₹735  \n",
       "99      ₹1,999  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame\n",
    "pd.DataFrame({'Shoes brand':brand,'Product Description':Product_Description,'Shoes Price':price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb4d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addb4572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78380455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d4af62f",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c27b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable and add path chromedrive path\n",
    "    # doc = Chrome(executable_path='C:\\chromedriver.exe')\n",
    "\n",
    "#upload chrome driver in jupiter notebook then use \n",
    "doc = Chrome(\"chromedriver.exe\")\n",
    "#open webpage\n",
    "#maximize window\n",
    "doc.maximize_window()\n",
    "#open chrome\n",
    "url = 'https://www.myntra.com/shoes'\n",
    "doc.get(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc36d7",
   "metadata": {},
   "source": [
    "# Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "76e64c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click color filter using xpath \n",
    "doc.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label').click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "975ea4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click price filter using xpath\n",
    "doc.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f2054",
   "metadata": {},
   "source": [
    "# And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f5dca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful scrap\n"
     ]
    }
   ],
   "source": [
    "#create 3 blank list variable \n",
    "brand_name = []\n",
    "description = []\n",
    "price = []\n",
    "\n",
    "#this for_loop run 2 time 1 page data only  50 shoes data\n",
    "for p in range(2):\n",
    "    if p == 1:\n",
    "        doc.find_element_by_xpath('//li[@class=\"pagination-next\"]//a').click()#click next page button\n",
    "        time.sleep(5)\n",
    "    else:\n",
    "        pass\n",
    "    for i in range(1,51):\n",
    "        #using x path scrape data\n",
    "        brand_name.append(doc.find_element_by_xpath(f'//ul[@class=\"results-base\"]//li[{i}]//h3').text)\n",
    "        description.append(doc.find_element_by_xpath(f'//ul[@class=\"results-base\"]//li[{i}]//h4').text)\n",
    "        price.append(doc.find_element_by_xpath(f'//ul[@class=\"results-base\"]//li[{i}]//div[@class=\"product-price\"]//span[1]').text.split('Rs. ')[1])\n",
    "        #if condition use after 50 data scraping click next page button \n",
    "        \n",
    "print('successful scrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bf8af64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoes Brand</th>\n",
       "      <th>Shoe description</th>\n",
       "      <th>Shoes Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Magnify Nitro Running</td>\n",
       "      <td>8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RARE RABBIT</td>\n",
       "      <td>Men Leather Flat Boots</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nautica</td>\n",
       "      <td>High-Top Block Heeled Boots</td>\n",
       "      <td>8699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ECCO</td>\n",
       "      <td>Women Textured Leather Sneakers</td>\n",
       "      <td>13999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ECCO</td>\n",
       "      <td>Women Ballerinas Flats</td>\n",
       "      <td>8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Calvin Klein</td>\n",
       "      <td>Men Solid Suede Sneakers</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Lightweight Sneakers</td>\n",
       "      <td>7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>MANGO</td>\n",
       "      <td>Textured High-Top Flat Boots</td>\n",
       "      <td>7990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Shoes Brand                 Shoe description Shoes Price\n",
       "0             Puma                Men Running Shoes        8449\n",
       "1             Puma        Men Magnify Nitro Running        8449\n",
       "2          Saint G       Women Leather Heeled Boots       13410\n",
       "3      RARE RABBIT           Men Leather Flat Boots        7999\n",
       "4          Nautica      High-Top Block Heeled Boots        8699\n",
       "..             ...                              ...         ...\n",
       "95            ECCO  Women Textured Leather Sneakers       13999\n",
       "96            ECCO           Women Ballerinas Flats        8999\n",
       "97    Calvin Klein         Men Solid Suede Sneakers        7999\n",
       "98  Tommy Hilfiger         Men Lightweight Sneakers        7999\n",
       "99           MANGO     Textured High-Top Flat Boots        7990\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all data in  dataframe using pandas\n",
    "pd.DataFrame({'Shoes Brand':brand_name,'Shoe description':description,'Shoes Price':price})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f502664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a3924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "831e4190",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0ff01517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable and add path chromedrive path\n",
    "    # doc = Chrome(executable_path='C:\\chromedriver.exe')\n",
    "\n",
    "#upload chrome driver in jupiter notebook then use \n",
    "doc = Chrome(\"chromedriver.exe\")\n",
    "#open webpage\n",
    "#maximize window\n",
    "doc.maximize_window()\n",
    "#open chrome\n",
    "url = 'https://www.amazon.in/'\n",
    "doc.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb71588",
   "metadata": {},
   "source": [
    "# Enter “Laptop” in the search field and then click the search icon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4a56ec8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using id enter laptop in search box\n",
    "doc.find_element_by_id('twotabsearchtextbox').send_keys('Laptop')\n",
    "#click search button\n",
    "doc.find_element_by_id('nav-search-submit-button').click()\n",
    "try:\n",
    "    doc.find_element_by_xpath('//div[@id=\"filter-p_n_feature_thirteen_browse-bin\"]//a[@id=\"p_n_feature_thirteen_browse-bin/16757431031\"]').click()\n",
    "except:\n",
    "    doc.find_element_by_xpath('//div[@id=\"filters\"]//li[11]//span[\"a-size-base a-color-base\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50599ec4",
   "metadata": {},
   "source": [
    "# scrape first 10 Intel Core i7 laptops data. scrape 3 attributesfor each laptop:\n",
    "    1. Title\n",
    "    2. Ratings\n",
    "    3. Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85787af1",
   "metadata": {},
   "source": [
    "# first 10 Intel Core i7 laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "51cf96e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful scrap\n"
     ]
    }
   ],
   "source": [
    "#locating Ratings\n",
    "urls=doc.find_elements_by_xpath(\"//a[@class='a-link-normal s-link-style a-text-normal']\")#collecting urls of all the laptop\n",
    "UR = []#blank list variable\n",
    "rating =[]#blank list variable\n",
    "title = []\n",
    "price = []\n",
    "#loop run for 10 times\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))\n",
    "    \n",
    "for url in UR:##loop for every laptop in the list\n",
    "    doc.get(url)\n",
    "    try:\n",
    "        ##appending the ratings in Ratings list\n",
    "        rating.append(doc.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\").text.split(\"out of\")[0])\n",
    "    except:\n",
    "        ##appending rating not show\n",
    "        rating.append(\"rating not show\")\n",
    "    finally:\n",
    "        title.append(doc.find_element_by_id('productTitle').text)\n",
    "        try:\n",
    "            price.append(doc.find_element_by_xpath('//table[@class=\"a-lineitem a-align-top\"]//td[@class=\"a-span12\"]').text)\n",
    "        except:\n",
    "            try:\n",
    "                price.append(doc.find_element_by_class_name('a-price-whole').text)\n",
    "            except:\n",
    "                price.append('price not show')\n",
    "            \n",
    "            \n",
    "print('successful scrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "042b1168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "#   first 10 Intel Core i7 laptops   #\n",
      "######################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td>₹89,990.00</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo ThinkBook Yoga 14s Intel Core i7 11th G...</td>\n",
       "      <td>₹86,990.00</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td>₹89,990.00</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>₹59,990.00</td>\n",
       "      <td>rating not show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...</td>\n",
       "      <td>₹96,990.00</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP Pavilion 14, Intel 11th Gen Core i7 16GB RA...</td>\n",
       "      <td>66,999</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...</td>\n",
       "      <td>₹79,990.00</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...</td>\n",
       "      <td>₹1,14,990.00</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td>₹82,990.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>₹85,990.00</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title         Price  \\\n",
       "0  Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...    ₹89,990.00   \n",
       "1  Lenovo ThinkBook Yoga 14s Intel Core i7 11th G...    ₹86,990.00   \n",
       "2  Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...    ₹89,990.00   \n",
       "3  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...    ₹59,990.00   \n",
       "4  ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...    ₹96,990.00   \n",
       "5  HP Pavilion 14, Intel 11th Gen Core i7 16GB RA...        66,999   \n",
       "6  Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...    ₹79,990.00   \n",
       "7  ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...  ₹1,14,990.00   \n",
       "8  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...    ₹82,990.00   \n",
       "9  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....    ₹85,990.00   \n",
       "\n",
       "            Rating  \n",
       "0             4.6   \n",
       "1             4.2   \n",
       "2             4.6   \n",
       "3  rating not show  \n",
       "4             3.9   \n",
       "5             4.4   \n",
       "6             4.3   \n",
       "7             4.8   \n",
       "8               4   \n",
       "9             4.4   "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame using pandas \n",
    "print('''######################################\n",
    "#   first 10 Intel Core i7 laptops   #\n",
    "######################################''')\n",
    "pd.DataFrame({'Title':title,'Price':price,'Rating':rating})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e47b08",
   "metadata": {},
   "source": [
    "# first 10 Intel Core i9 laptops "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "41575799",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = 'https://www.amazon.in/'\n",
    "doc.get(url)\n",
    "time.sleep(3)\n",
    "#using id enter laptop in search box\n",
    "doc.find_element_by_id('twotabsearchtextbox').send_keys('Laptop')\n",
    "time.sleep(1)\n",
    "#click search button\n",
    "doc.find_element_by_id('nav-search-submit-button').click()\n",
    "#click intel core i9\n",
    "time.sleep(3)\n",
    "doc.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[5]/ul[2]/li[12]/span/a/span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d38b0ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful scrap\n"
     ]
    }
   ],
   "source": [
    "#locating Ratings\n",
    "urls=doc.find_elements_by_xpath(\"//a[@class='a-link-normal s-link-style a-text-normal']\")#collecting urls of all the laptop\n",
    "UR = []#blank list variable\n",
    "rating =[]#blank list variable\n",
    "title = []\n",
    "price = []\n",
    "#loop run for 10 times\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))\n",
    "    \n",
    "for url in UR:##loop for every laptop in the list\n",
    "    doc.get(url)\n",
    "    try:\n",
    "        ##appending the ratings in Ratings list\n",
    "        rating.append(doc.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\").text.split(\"out of\")[0])\n",
    "    except:\n",
    "        ##appending rating not show\n",
    "        rating.append(\"rating not show\")\n",
    "    finally:\n",
    "        title.append(doc.find_element_by_id('productTitle').text)\n",
    "        try:\n",
    "            price.append(doc.find_element_by_xpath('//div[@id=\"newAccordionRow\"]//h5').text.split('   ')[1])\n",
    "        except:\n",
    "            try:\n",
    "                price.append(doc.find_element_by_class_name('a-price-whole').text)\n",
    "            except:\n",
    "                price.append('price not show')\n",
    "            \n",
    "            \n",
    "print('successful scrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ccdbc4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################\n",
      "#   first 10 Intel Core i9 laptops   #\n",
      "######################################\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>144,990.00</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...</td>\n",
       "      <td>143,990.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...</td>\n",
       "      <td>2,65,999</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell XPS 17 (2021) i9-11900H Touch Screen Lapt...</td>\n",
       "      <td>3,25,500</td>\n",
       "      <td>rating not show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Precision 5550 || i9 -10885H || 16GB || 1...</td>\n",
       "      <td>200,000.00</td>\n",
       "      <td>rating not show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...</td>\n",
       "      <td>205,990.00</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...</td>\n",
       "      <td>139,990.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell G7 7500 15.6inch FHD 300 Hz Dis...</td>\n",
       "      <td>2,05,990</td>\n",
       "      <td>rating not show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Z2 G5 Workstation 700W /Core i9-10900 (2.8GHz ...</td>\n",
       "      <td>2,39,000</td>\n",
       "      <td>rating not show</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title       Price  \\\n",
       "0  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...  144,990.00   \n",
       "1  ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...  143,990.00   \n",
       "2  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...    2,65,999   \n",
       "3  Dell XPS 17 (2021) i9-11900H Touch Screen Lapt...    3,25,500   \n",
       "4  Dell Precision 5550 || i9 -10885H || 16GB || 1...  200,000.00   \n",
       "5  Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...  205,990.00   \n",
       "6  ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...  139,990.00   \n",
       "7  (Renewed) Dell G7 7500 15.6inch FHD 300 Hz Dis...    2,05,990   \n",
       "8  Z2 G5 Workstation 700W /Core i9-10900 (2.8GHz ...    2,39,000   \n",
       "\n",
       "            Rating  \n",
       "0             4.1   \n",
       "1               4   \n",
       "2             4.4   \n",
       "3  rating not show  \n",
       "4  rating not show  \n",
       "5             4.1   \n",
       "6               5   \n",
       "7  rating not show  \n",
       "8  rating not show  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create data frame using pandas \n",
    "print('''######################################\n",
    "#   first 10 Intel Core i9 laptops   #\n",
    "######################################''')\n",
    "pd.DataFrame({'Title':title,'Price':price,'Rating':rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7aaa82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9785a426",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noidalocation. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "    This task will be done in following steps:\n",
    "    1. First get the webpage https://www.ambitionbox.com/\n",
    "    2. Click on the Job option as shown in the image\n",
    "    3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "    “Data Scientist” and click on search button.\n",
    "    4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "    “Noida” and select location “Noida”.\n",
    "    5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "    6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "43465763",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable and add path chromedrive path\n",
    "    # doc = Chrome(executable_path='C:\\chromedriver.exe')\n",
    "\n",
    "#upload chrome driver in jupiter notebook then use \n",
    "doc = Chrome(\"chromedriver.exe\")\n",
    "#open webpage\n",
    "#maximize window\n",
    "doc.maximize_window()\n",
    "#open chrome\n",
    "url = 'https://www.ambitionbox.com/'\n",
    "doc.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f2a14",
   "metadata": {},
   "source": [
    "# 2. Click on the Job option as shown in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e14b4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click salaries button using css_selector\n",
    "doc.find_element_by_css_selector('a[title=\"Jobs\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5844d091",
   "metadata": {},
   "source": [
    "# 3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter“Data Scientist” and click on search button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "93787404",
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter Data Scientist using css selecter then add data scientist\n",
    "doc.find_element_by_css_selector('input[title=\"Enter Designation, Company or a Skill\"]').send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "87b4d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click search button using class_name\n",
    "doc.find_element_by_class_name('ctas-btn-medium').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540e3b4",
   "metadata": {},
   "source": [
    "# 4. You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f79e192",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#click location button using css selector\n",
    "doc.find_element_by_css_selector('div[title=\"Location\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f35e04cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter noida in search box\n",
    "doc.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input').send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a79d7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select noida in list\n",
    "doc.find_element_by_xpath('/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e898d",
   "metadata": {},
   "source": [
    "# 5. Then scrape the data for the first 10 jobs results you get on the above shown page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8025980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f4743981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful scrap\n"
     ]
    }
   ],
   "source": [
    "#create 6 blank list variable\n",
    "company_name = []\n",
    "job_posted = []\n",
    "Rating = []\n",
    "\n",
    "#for _loop run 10 times\n",
    "for i in range(1,11):\n",
    "    #     using xpath extract text then text append 10 time into list \n",
    "    company_name.append(doc.find_element_by_xpath(f'/html/body/div/div/div/div[2]/div[2]/div[2]/div[2]/div/div[1]/div[{i}]/div[2]/div/p').text)\n",
    "    job_posted.append(doc.find_element_by_xpath(f'/html/body/div/div/div/div[2]/div[2]/div[2]/div[2]/div/div[1]/div[{i}]/div[3]/span[1]').text)\n",
    "    Rating.append(doc.find_element_by_xpath(f'/html/body/div/div/div/div[2]/div[2]/div[2]/div[2]/div/div[1]/div[{i}]/div[2]/div/div/a[1]/span').text)\n",
    "\n",
    "print('successful scrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9ea8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "326501f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>job was posted</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nokia Solutions and Networks India (P)Ltd.</td>\n",
       "      <td>7d ago</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Electronics India Pvt. Ltd.</td>\n",
       "      <td>28d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>23hr ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>18d ago</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>2d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>3d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>14d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>14d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>14d ago</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>22d ago</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Company Name job was posted Rating\n",
       "0  Nokia Solutions and Networks India (P)Ltd.         7d ago    4.3\n",
       "1              LG Electronics India Pvt. Ltd.        28d ago    4.1\n",
       "2                                       Paytm       23hr ago    3.7\n",
       "3                  Jubilant Foodworks Limited        18d ago    3.9\n",
       "4                                CHT Sapiense         2d ago    3.7\n",
       "5                                CHT Sapiense         3d ago    3.7\n",
       "6                                    GI Group        14d ago    4.1\n",
       "7                                    GI Group        14d ago    4.1\n",
       "8                                    GI Group        14d ago    4.1\n",
       "9                                       Paytm        22d ago    3.7"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas create dataframe\n",
    "pd.DataFrame({'Company Name':company_name,'job was posted':job_posted,'Rating':Rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312ac88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018194f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1692c586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a78f5c2",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "    You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "    The above task will be, done as shown in the below steps:\n",
    "    1. First get the webpage https://www.ambitionbox.com/\n",
    "    2. Click on the salaries option as shown in the image.\n",
    "    3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "    then click on “Data Scientist”.\n",
    "    4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "    salary, minimum salary, maximum salary, experience required.\n",
    "    5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513712d",
   "metadata": {},
   "source": [
    "# 1. First get the webpage https://www.ambitionbox.com/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3129b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create variable and add path chromedrive path\n",
    "    # doc = Chrome(executable_path='C:\\chromedriver.exe')\n",
    "\n",
    "#upload chrome driver in jupiter notebook then use \n",
    "doc = Chrome(\"chromedriver.exe\")\n",
    "#open webpage\n",
    "#maximize window\n",
    "doc.maximize_window()\n",
    "#open chrome\n",
    "url = 'https://www.ambitionbox.com/'\n",
    "doc.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdef725",
   "metadata": {},
   "source": [
    "# 2. Click on the salaries option as shown in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b022fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click salaries button using css_selector\n",
    "doc.find_element_by_css_selector('a[title=\"Company Salaries\"]').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b9a0f",
   "metadata": {},
   "source": [
    "# 3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "11affc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter \"Data Scientist\" using id\n",
    "enter_data = doc.find_element_by_id(\"jobProfileSearchbox\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "087da767",
   "metadata": {},
   "outputs": [],
   "source": [
    "enter_data.send_keys('Data Scientist')#enter Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7af80e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click data scientis\n",
    "doc.find_element_by_class_name('tt_text').click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af74d7d",
   "metadata": {},
   "source": [
    "# 4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "41133f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful scrap\n"
     ]
    }
   ],
   "source": [
    "#create 6 blank list variable \n",
    "company_name = []\n",
    "salary_record = []\n",
    "average_salary = []\n",
    "minimum_salary = []\n",
    "maximum_salary = []\n",
    "experience_required = []\n",
    "\n",
    "#for_loop run 10 times\n",
    "for i in range(1,11):\n",
    "#     using xpath extract text then text append 10 time into list \n",
    "    company_name.append(doc.find_element_by_xpath(f'/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[{i}]/div[1]/div/div/div[1]/a').text)\n",
    "    salary_record.append(doc.find_element_by_xpath(f'/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[{i}]/div[1]/div/div/div[1]/span').text)\n",
    "    average_salary.append(doc.find_element_by_xpath(f'/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[{i}]/div[2]/div/div[1]/div/p').text)\n",
    "    minimum_salary.append(doc.find_element_by_xpath(f'/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[{i}]/div[2]/div/div[2]/div[1]').text)\n",
    "    maximum_salary.append(doc.find_element_by_xpath(f'/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[{i}]/div[2]/div/div[2]/div[2]').text)\n",
    "    experience_required.append(doc.find_element_by_xpath(f'/html/body/div/div/div/main/section[1]/div[2]/div[3]/div[2]/div[{i}]/div[1]/div/div/div[2]').text.split('\\n')[2])\n",
    "    \n",
    "print('successful scrap')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575976a0",
   "metadata": {},
   "source": [
    "# 5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30b67702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Salary Record</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 28.7L</td>\n",
       "      <td>₹ 17.7L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "      <td>3 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>₹ 19.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 72 salaries</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 23 salaries</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 7.2L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>4 yrs exp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 42 salaries</td>\n",
       "      <td>₹ 11.9L</td>\n",
       "      <td>₹ 5.8L</td>\n",
       "      <td>₹ 21.5L</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name         Salary Record Average Salary  \\\n",
       "0                   Walmart  based on 10 salaries        ₹ 28.7L   \n",
       "1                  Ab Inbev  based on 22 salaries        ₹ 19.5L   \n",
       "2                        ZS  based on 14 salaries        ₹ 15.8L   \n",
       "3         Fractal Analytics  based on 72 salaries        ₹ 15.0L   \n",
       "4                     Optum  based on 23 salaries        ₹ 15.0L   \n",
       "5              UnitedHealth  based on 49 salaries        ₹ 13.5L   \n",
       "6           Tiger Analytics  based on 27 salaries        ₹ 13.5L   \n",
       "7                   Verizon  based on 14 salaries        ₹ 12.7L   \n",
       "8  Ganit Business Solutions  based on 13 salaries        ₹ 12.4L   \n",
       "9                  Ericsson  based on 42 salaries        ₹ 11.9L   \n",
       "\n",
       "  Minimum Salary Maximum Salary Experience Required  \n",
       "0        ₹ 17.7L        ₹ 35.0L           3 yrs exp  \n",
       "1        ₹ 15.0L        ₹ 25.0L         3-4 yrs exp  \n",
       "2         ₹ 9.8L        ₹ 20.0L           2 yrs exp  \n",
       "3         ₹ 9.5L        ₹ 22.0L         2-4 yrs exp  \n",
       "4        ₹ 11.0L        ₹ 21.3L         3-4 yrs exp  \n",
       "5         ₹ 7.2L        ₹ 20.5L         2-4 yrs exp  \n",
       "6         ₹ 8.3L        ₹ 18.5L         3-4 yrs exp  \n",
       "7        ₹ 10.0L        ₹ 21.0L           4 yrs exp  \n",
       "8         ₹ 8.5L        ₹ 15.0L           4 yrs exp  \n",
       "9         ₹ 5.8L        ₹ 21.5L         3-4 yrs exp  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas create dataframe\n",
    "pd.DataFrame({'Company Name':company_name,'Salary Record':salary_record,'Average Salary':average_salary,'Minimum Salary':minimum_salary,'Maximum Salary':maximum_salary,'Experience Required':experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1928c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b181a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a91858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf619c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedec365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab9ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7512662b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46acf180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
